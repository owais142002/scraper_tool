{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c71cc40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import concurrent.futures\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "def ethiopianProperties():\n",
    "    def sendData(data, columns, collectionName):\n",
    "        try:\n",
    "            print(f'Collected {len(data)} records!')\n",
    "            df = pd.DataFrame(data, columns=columns)\n",
    "            mongo_insert_data=df.to_dict('records')\n",
    "            print('Sending Data to MongoDB!')\n",
    "\n",
    "            def get_database():\n",
    "                CONNECTION_STRING = \"mongodb+srv://david:0pFvuYveY8EIwWDs@cluster0.gfzw4mh.mongodb.net/?retryWrites=true&w=majority\"\n",
    "                client = MongoClient(CONNECTION_STRING)\n",
    "                return client[databaseName]\n",
    "\n",
    "            dbname = get_database()\n",
    "            collection_name = dbname[collectionName]\n",
    "            for index,instance in enumerate(mongo_insert_data):\n",
    "                collection_name.update_one({'url':instance['url']},{'$set':instance},upsert=True)\n",
    "            print('Data sent to MongoDB successfully')\n",
    "\n",
    "        except Exception as e:\n",
    "            print('Some error occured while sending data MongoDB! Following is the error.')\n",
    "            print(e)\n",
    "            print('-----------------------------------------')\n",
    "\n",
    "    def scrape_data(link):\n",
    "        retries = 3\n",
    "        delay = 10\n",
    "        while retries > 0:\n",
    "            try:\n",
    "                response = requests.get(link[0], headers=headers, timeout=180)\n",
    "                soup = BeautifulSoup(response.content, 'lxml')\n",
    "                if soup.find(\"span\", text=\"404 - Page Not Found!\"):\n",
    "                    print('not found', link[0])\n",
    "                    return\n",
    "\n",
    "                propertyTitle = soup.select_one('h1.page-title').text if soup.select_one('h1.page-title') else None\n",
    "                propertyId = soup.select_one('h4.title').text.split(':')[1].strip() if (len(soup.select_one('h4.title').text.split(':')) > 1) else None\n",
    "                priceLst = soup.select_one('h5.price span:nth-child(2)').text.strip().split('-')[0].strip().replace('$', '').replace(',', '') if soup.select_one('h5.price span:nth-child(2)') else None\n",
    "                price = priceLst.split(' ')[0]\n",
    "                currency, priceStatus, priceDiff = None, None, None\n",
    "                if (price is not None and price != ''):\n",
    "                    price = float(price)  \n",
    "                    currency = \"USD\"\n",
    "\n",
    "                    data = singleItem.find_one({\"url\": link[0]})\n",
    "                    oldPrice = data['price'] if data else None\n",
    "                    priceDiff = max(oldPrice, price) - min(oldPrice, price) if oldPrice else 0\n",
    "                    if price != oldPrice:\n",
    "                        priceStatus = 'increased' if (price > oldPrice) else 'decreased'\n",
    "                    else:\n",
    "                        priceStatus = None\n",
    "\n",
    "                priceType = ' '.join(priceLst.split(' ')[1:])\n",
    "                listingType = soup.select_one('h5.price span').text.strip()\n",
    "                imgUrls = [a['href'] for a in soup.select('ul.slides li a')]\n",
    "                features = [feature.text for feature in soup.select('ul.arrow-bullet-list.clearfix a')]\n",
    "                city = soup.select_one('nav.property-breadcrumbs li:nth-of-type(2)').text if soup.select_one('nav.property-breadcrumbs li:nth-of-type(2)') else None\n",
    "                neighbourhood = soup.select_one('nav.property-breadcrumbs li:nth-of-type(3)').text if soup.select_one('nav.property-breadcrumbs li:nth-of-type(3)') else None\n",
    "\n",
    "                props = [prop.text.replace('\\n', '').replace('\\xa0', '') for prop in soup.select('div.property-meta.clearfix span')[:-3]]\n",
    "                beds, baths, garage, size = None, None, None, None\n",
    "                for i in props:\n",
    "                    if 'Bedroom' in i:\n",
    "                        beds = float(i.replace('Bedroom', '').replace('s', ''))\n",
    "                    elif 'Bathroom' in i:\n",
    "                        baths = float(i.replace('Bathroom', '').replace('s', ''))\n",
    "                    elif 'Garage' in i:\n",
    "                        garage = float(i.replace('Garage', '').replace('s', ''))\n",
    "                    else:\n",
    "                        size = i\n",
    "\n",
    "                content = \"\\n\".join([desc.text for desc in soup.select('div.content.clearfix')]).replace('\\xa0', '')\n",
    "                description = '\\n'.join(content.split('Additional Amenities')[0].strip().split('\\n'))\n",
    "                amenities = content.split('Additional Amenities')[1].strip().split('\\n') if (len(content.split('Additional Amenities')) > 1) else []\n",
    "                agentNumber = soup.select('li.office')[0].text.replace('\\n', '').replace('\\t', '').split(':')[1].strip() if soup.select('li.office') else \"+251-911-088-114\"\n",
    "                #print(link[0], propertyTitle, propertyId, price, priceType if (priceType != \"\") else None, listingType, imgUrls, features, beds, baths, garage, size, description, amenities)\n",
    "#                 print(link[0], propertyTitle, propertyId)\n",
    "#                 print('')\n",
    "\n",
    "            except (requests.exceptions.Timeout, requests.exceptions.SSLError):\n",
    "                print(\"Timeout error occurred. Retrying in {} seconds...\".format(delay))\n",
    "                retries -= 1\n",
    "                time.sleep(delay)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to scrape data for {link[0]}: {e}\")\n",
    "\n",
    "            finally:\n",
    "                try:\n",
    "                    all_data.append([propertyTitle, propertyId, link[0], price if (price != '') else None, currency if (price != '') else None, float(priceDiff) if (priceDiff != '' and priceDiff is not None) else None, priceStatus, True if (priceDiff is not None and (priceDiff > 0 and priceDiff != '')) else False, priceType if (priceType != '') else None, listingType, imgUrls, features, beds, baths, garage, size, description, amenities, \"AgentÂ Admin\", agentNumber, city, neighbourhood])\n",
    "                    return\n",
    "                except:\n",
    "                    continue\n",
    "        print(f\"Max retries reached. Could not scrape {link[0]}\")\n",
    "\n",
    "    def getData():\n",
    "        print(\"Fetching Stored URLs.\")\n",
    "        print('')\n",
    "        CONNECTION_STRING = \"mongodb+srv://david:0pFvuYveY8EIwWDs@cluster0.gfzw4mh.mongodb.net/?retryWrites=true&w=majority\"\n",
    "        client = MongoClient(CONNECTION_STRING)\n",
    "\n",
    "        db = client['EthiopianProperties']\n",
    "        collection = db['propertyURLs']\n",
    "        data = collection.find()\n",
    "        return list(data)\n",
    "\n",
    "    def continous_connection():\n",
    "        CONNECTION_STRING = \"mongodb+srv://david:0pFvuYveY8EIwWDs@cluster0.gfzw4mh.mongodb.net/?retryWrites=true&w=majority\"\n",
    "        clientC = MongoClient(CONNECTION_STRING)\n",
    "        db = clientC['EthiopianProperties']\n",
    "        return db['propertyURLs']\n",
    "\n",
    "\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36',\n",
    "        'Accept-Language': 'en-US,en;q=0.5',\n",
    "        'Accept-Encoding': 'gzip, deflate, br',\n",
    "        'Connection': 'keep-alive',\n",
    "        'Upgrade-Insecure-Requests': '1'\n",
    "    }\n",
    "    databaseName='EthiopianProperties'\n",
    "    columns=['propertyTitle', 'propertyId', 'url', 'price', 'currency', 'priceDiff', 'priceStatus', 'priceChange', 'pricingCriteria', 'listingType', 'imgUrls', 'features', 'beds', 'baths', 'garage', 'size', 'description', 'amenities', 'agent', 'agentNumber', 'city', 'neighbourhood']\n",
    "    opt = 2\n",
    "    threads = 4\n",
    "\n",
    "\n",
    "    links, all_data = [], []\n",
    "    if opt == 2:\n",
    "        datas = getData()\n",
    "        links = [list(data['url'].strip().split()) for data in datas]\n",
    "\n",
    "        singleItem = continous_connection()\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers=threads) as executor:\n",
    "            executor.map(scrape_data, links)\n",
    "\n",
    "        sendData(all_data, columns, 'propertyDetails')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfaf37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ethiopianProperties()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7187f778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
